{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dc8801c",
   "metadata": {},
   "source": [
    "1. Load the Data\n",
    "Question: Load the dataset using pandas. What is the shape of the dataset? Print the first 5 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f49610b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset:\n",
      "(500, 7)\n",
      "\n",
      "First 5 rows of the dataset:\n",
      "   CustomerID         Name   Age     Product  Purchase_Amount Purchase Date  \\\n",
      "0        1000  Steve Davis  51.0      Laptop              NaN    2024-04-20   \n",
      "1        1001  Jane Miller  36.0      Tablet          1805.62    2024-12-22   \n",
      "2        1002    Bob Smith  46.0      Tablet           168.44    2024-04-20   \n",
      "3        1003   Emma Brown  51.0  Smartphone              NaN    2024-01-28   \n",
      "4        1004  Sara Miller  50.0      Tablet           267.39    2024-03-15   \n",
      "\n",
      "  Region  \n",
      "0  South  \n",
      "1  South  \n",
      "2  South  \n",
      "3   West  \n",
      "4  South  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"C:/Users/SPF_Admin/Downloads/sales_data_week1_500rows.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# What is the shape of the dataset?\n",
    "print(\"Shape of the dataset:\")\n",
    "print(df.shape)\n",
    "\n",
    "# Print the first 5 rows.\n",
    "print(\"\\nFirst 5 rows of the dataset:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5c8e3f",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "- import pandas as pd: This line imports the pandas library and assigns it the alias pd, which is a common convention.\n",
    "- file_path = \"sales_data_week1_500rows.csv\": This line defines the path to your CSV file.\n",
    "- df = pd.read_csv(file_path): This function reads the data from the specified CSV file and loads it into a pandas DataFrame called df. A DataFrame is a 2-dimensional labeled data structure with columns of potentially different types, similar to a spreadsheet or SQL table.\n",
    "- print(df.shape): The .shape attribute of a DataFrame returns a tuple representing its dimensions (number of rows, number of columns).\n",
    "- print(df.head()): The .head() method, by default, returns the first 5 rows of the DataFrame. You can pass an integer argument (e.g., df.head(10)) to get a different number of rows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec03ec7",
   "metadata": {},
   "source": [
    "2. Missing Values\n",
    "- Question: How many missing values are there in each column?\n",
    "  - Drop all rows where the Name or Product is missing.\n",
    "  - Fill missing Region values with 'Unknown'.\n",
    "  - Fill missing Purchase_Amount with the mean of the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80c125bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values in each column (before handling):\n",
      "CustomerID           0\n",
      "Name                 4\n",
      "Age                 21\n",
      "Product             87\n",
      "Purchase_Amount     26\n",
      "Purchase Date        0\n",
      "Region             102\n",
      "dtype: int64\n",
      "\n",
      "Shape after dropping rows with missing Name or Product: (410, 7)\n",
      "\n",
      "Missing values in 'Region' after filling:\n",
      "0\n",
      "\n",
      "Missing values in 'Purchase_Amount' after filling:\n",
      "0\n",
      "\n",
      "Missing values in each column (after handling specific columns):\n",
      "CustomerID          0\n",
      "Name                0\n",
      "Age                17\n",
      "Product             0\n",
      "Purchase_Amount     0\n",
      "Purchase Date       0\n",
      "Region              0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SPF_Admin\\AppData\\Local\\Temp\\ipykernel_20820\\4199667703.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Region'].fillna('Unknown', inplace=True)\n",
      "C:\\Users\\SPF_Admin\\AppData\\Local\\Temp\\ipykernel_20820\\4199667703.py:21: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Purchase_Amount'].fillna(mean_purchase_amount, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# How many missing values are there in each column?\n",
    "print(\"\\nMissing values in each column (before handling):\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Drop all rows where the Name or Product is missing.\n",
    "# The inplace=True argument modifies the DataFrame directly.\n",
    "df.dropna(subset=['Name', 'Product'], inplace=True)\n",
    "print(f\"\\nShape after dropping rows with missing Name or Product: {df.shape}\")\n",
    "\n",
    "# Fill missing Region values with 'Unknown'.\n",
    "df['Region'].fillna('Unknown', inplace=True)\n",
    "print(\"\\nMissing values in 'Region' after filling:\")\n",
    "print(df['Region'].isnull().sum()) # Should be 0\n",
    "\n",
    "# Fill missing Purchase_Amount with the mean of the column.\n",
    "# First, ensure 'Purchase_Amount' is numeric, converting if necessary\n",
    "if df['Purchase_Amount'].dtype == 'object':\n",
    "    df['Purchase_Amount'] = pd.to_numeric(df['Purchase_Amount'], errors='coerce')\n",
    "    \n",
    "mean_purchase_amount = df['Purchase_Amount'].mean()\n",
    "df['Purchase_Amount'].fillna(mean_purchase_amount, inplace=True)\n",
    "print(\"\\nMissing values in 'Purchase_Amount' after filling:\")\n",
    "print(df['Purchase_Amount'].isnull().sum()) # Should be 0\n",
    "\n",
    "print(\"\\nMissing values in each column (after handling specific columns):\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9b246c",
   "metadata": {},
   "source": [
    "- df.isnull(): This method returns a DataFrame of the same shape as df but with boolean values: True for missing (NaN) values and False otherwise.\n",
    "- .sum(): When applied after isnull(), this sums the True values (which are treated as 1) for each column, giving the count of missing values per column.\n",
    "- df.dropna(subset=['Name', 'Product'], inplace=True):\n",
    "  - .dropna(): This method is used to remove missing values.\n",
    "  - subset=['Name', 'Product']: This specifies that rows should be dropped only if there are missing values in the 'Name' OR 'Product' columns.\n",
    "  - inplace=True: This modifies the DataFrame df directly. Without it, the method would return a new DataFrame with the rows dropped, and df would remain unchanged.\n",
    "- df['Region'].fillna('Unknown', inplace=True):\n",
    "  - .fillna(): This method is used to fill missing (NaN) values.\n",
    "  - 'Unknown': This is the value used to replace missing entries in the 'Region' column.\n",
    "- pd.to_numeric(df['Purchase_Amount'], errors='coerce'): This line attempts to convert the 'Purchase_Amount' column to a numeric type. If any values cannot be converted, errors='coerce' will replace them with NaN (Not a Number). This is important if the column was read as strings (objects) due to non-numeric characters.\n",
    "- mean_purchase_amount = df['Purchase_Amount'].mean(): This calculates the mean of the 'Purchase_Amount' column, automatically ignoring any NaN values.\n",
    "- df['Purchase_Amount'].fillna(mean_purchase_amount, inplace=True): This fills the missing NaN values in the 'Purchase_Amount' column with the calculated mean."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4becf765",
   "metadata": {},
   "source": [
    "3. Data Type and Conversion\n",
    "- Convert the Purchase Date column to datetime format.\n",
    "- Create a new column called Purchase_Year extracted from the Purchase Date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9747250b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data types after 'Purchase Date' conversion:\n",
      "Purchase Date    datetime64[ns]\n",
      "Purchase_Year             int32\n",
      "dtype: object\n",
      "\n",
      "First 5 rows showing 'Purchase Date' and 'Purchase_Year':\n",
      "  Purchase Date  Purchase_Year\n",
      "0    2024-04-20           2024\n",
      "1    2024-12-22           2024\n",
      "2    2024-04-20           2024\n",
      "3    2024-01-28           2024\n",
      "4    2024-03-15           2024\n"
     ]
    }
   ],
   "source": [
    "# Convert the Purchase Date column to datetime format.\n",
    "# Using errors='coerce' will turn unparseable dates into NaT (Not a Time).\n",
    "if 'Purchase Date' in df.columns: # Check if column exists before processing\n",
    "    df['Purchase Date'] = pd.to_datetime(df['Purchase Date'], errors='coerce')\n",
    "\n",
    "    # Create a new column called Purchase_Year extracted from the Purchase Date.\n",
    "    # The .dt accessor is used to access datetime-like properties.\n",
    "    df['Purchase_Year'] = df['Purchase Date'].dt.year\n",
    "\n",
    "    print(\"\\nData types after 'Purchase Date' conversion:\")\n",
    "    print(df[['Purchase Date', 'Purchase_Year']].dtypes)\n",
    "    print(\"\\nFirst 5 rows showing 'Purchase Date' and 'Purchase_Year':\")\n",
    "    print(df[['Purchase Date', 'Purchase_Year']].head())\n",
    "else:\n",
    "    print(\"\\n'Purchase Date' column not found for conversion.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448865f2",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "- pd.to_datetime(df['Purchase Date'], errors='coerce'): This function converts the 'Purchase Date' column to pandas datetime objects.\n",
    "  - errors='coerce': If any date string cannot be parsed into a valid date, it will be set to NaT (Not a Time), which is pandas' equivalent of NaN for datetime objects.\n",
    "- df['Purchase Date'].dt.year:\n",
    "  - .dt: This is an accessor object for datetime-like properties of the Series (in this case, the 'Purchase Date' column, which is now a Series of datetime objects).\n",
    "  - .year: This extracts the year component from each datetime object in the Series.\n",
    "The result is assigned to a new column called 'Purchase_Year'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909282de",
   "metadata": {},
   "source": [
    "4. Column Renaming and Formatting\n",
    "- Rename all columns to lowercase and replace spaces with underscores (e.g., Purchase Date → purchase_date).\n",
    "- Rename purchase_amount to amount_usd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db228e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Column names after converting to lowercase and replacing spaces:\n",
      "['customerid', 'name', 'age', 'product', 'purchase_amount', 'purchase_date', 'region', 'purchase_year']\n",
      "\n",
      "Column names after renaming 'purchase_amount' to 'amount_usd':\n",
      "['customerid', 'name', 'age', 'product', 'amount_usd', 'purchase_date', 'region', 'purchase_year']\n",
      "\n",
      "First 5 rows after all column renaming:\n",
      "   customerid         name   age     product   amount_usd purchase_date  \\\n",
      "0        1000  Steve Davis  51.0      Laptop  1057.789098    2024-04-20   \n",
      "1        1001  Jane Miller  36.0      Tablet  1805.620000    2024-12-22   \n",
      "2        1002    Bob Smith  46.0      Tablet   168.440000    2024-04-20   \n",
      "3        1003   Emma Brown  51.0  Smartphone  1057.789098    2024-01-28   \n",
      "4        1004  Sara Miller  50.0      Tablet   267.390000    2024-03-15   \n",
      "\n",
      "  region  purchase_year  \n",
      "0  South           2024  \n",
      "1  South           2024  \n",
      "2  South           2024  \n",
      "3   West           2024  \n",
      "4  South           2024  \n"
     ]
    }
   ],
   "source": [
    "# Rename all columns to lowercase and replace spaces with underscores.\n",
    "original_columns = df.columns.tolist() # Save original for comparison if needed\n",
    "df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
    "print(\"\\nColumn names after converting to lowercase and replacing spaces:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# Rename purchase_amount to amount_usd.\n",
    "# First, check if 'purchase_amount' (now 'purchase_amount' if it existed) is in the new column names\n",
    "if 'purchase_amount' in df.columns:\n",
    "    df.rename(columns={'purchase_amount': 'amount_usd'}, inplace=True)\n",
    "    print(\"\\nColumn names after renaming 'purchase_amount' to 'amount_usd':\")\n",
    "    print(df.columns.tolist())\n",
    "elif 'amount_usd' in df.columns: # If it was already named amount_usd (e.g. if original was Amount_USD)\n",
    "    print(\"\\nColumn 'amount_usd' already exists or 'purchase_amount' was not found.\")\n",
    "else:\n",
    "    print(\"\\nNeither 'purchase_amount' nor 'amount_usd' found for renaming operation.\")\n",
    "\n",
    "\n",
    "print(\"\\nFirst 5 rows after all column renaming:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a6322c",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "- df.columns.str.lower(): This converts all column names to lowercase. df.columns returns an Index object containing column labels, and .str provides access to string methods for each element.\n",
    "- .str.replace(' ', '_'): This replaces all spaces in the column names with underscores.\n",
    "- df.rename(columns={'old_name': 'new_name'}, inplace=True):\n",
    "  - .rename(): This method is used to alter axes labels.\n",
    "  - columns={'purchase_amount': 'amount_usd'}: This dictionary specifies the mapping from the old column name ('purchase_amount') to the new column name ('amount_usd').\n",
    "  - inplace=True: Modifies the DataFrame directly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360405b1",
   "metadata": {},
   "source": [
    "5. Filtering and Sorting\n",
    "- Filter rows where amount_usd is greater than 1000.\n",
    "- Sort the filtered data by amount_usd in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce9ea30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of data filtered by amount_usd > 1000: (236, 8)\n",
      "\n",
      "First 5 rows of filtered (amount_usd > 1000) and sorted data:\n",
      "     customerid        name   age     product  amount_usd purchase_date  \\\n",
      "469        1469  Sara Davis  23.0  Smartphone     1991.76    2024-07-22   \n",
      "435        1435    Jane Ali   NaN      Laptop     1987.35    2024-02-09   \n",
      "315        1315     Bob Lee  57.0  Smartphone     1979.56    2024-10-19   \n",
      "258        1258  Emma Brown  22.0      Laptop     1975.28    2024-01-13   \n",
      "310        1310   Linda Lee  50.0      Laptop     1974.03    2024-08-20   \n",
      "\n",
      "      region  purchase_year  \n",
      "469    North           2024  \n",
      "435     East           2024  \n",
      "315  Unknown           2024  \n",
      "258     West           2024  \n",
      "310     West           2024  \n"
     ]
    }
   ],
   "source": [
    "# Ensure 'amount_usd' column exists and is numeric for filtering.\n",
    "if 'amount_usd' in df.columns:\n",
    "    # Convert to numeric just in case it was misinterpreted, coercing errors to NaN\n",
    "    df['amount_usd'] = pd.to_numeric(df['amount_usd'], errors='coerce')\n",
    "    # Drop rows if amount_usd became NaN after coercion, which can happen if it had non-numeric text\n",
    "    df.dropna(subset=['amount_usd'], inplace=True)\n",
    "\n",
    "    # Filter rows where amount_usd is greater than 1000.\n",
    "    # Using .copy() is good practice here to avoid SettingWithCopyWarning on the new DataFrame.\n",
    "    df_filtered = df[df['amount_usd'] > 1000].copy()\n",
    "    print(f\"\\nShape of data filtered by amount_usd > 1000: {df_filtered.shape}\")\n",
    "\n",
    "    # Sort the filtered data by amount_usd in descending order.\n",
    "    df_sorted = df_filtered.sort_values(by='amount_usd', ascending=False)\n",
    "\n",
    "    print(\"\\nFirst 5 rows of filtered (amount_usd > 1000) and sorted data:\")\n",
    "    print(df_sorted.head())\n",
    "else:\n",
    "    print(\"\\n'amount_usd' column not found for filtering and sorting.\")\n",
    "    df_sorted = pd.DataFrame() # Create an empty DataFrame if column doesn't exist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86a7db0",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "- df['amount_usd'] = pd.to_numeric(df['amount_usd'], errors='coerce'): Ensures the column is numeric.\n",
    "- df.dropna(subset=['amount_usd'], inplace=True): Removes any rows where amount_usd became NaN during numeric conversion.\n",
    "- df[df['amount_usd'] > 1000]: This is boolean indexing.\n",
    "  - df['amount_usd'] > 1000: This part creates a boolean Series (True/False) where True corresponds to rows where the 'amount_usd' is greater than 1000.\n",
    "  - df[...]: Passing this boolean Series inside the square brackets of the DataFrame df selects only the rows where the condition is True.\n",
    "  - .copy(): Creates a new DataFrame df_filtered rather than a view, preventing potential SettingWithCopyWarning if df_filtered is modified later.\n",
    "- df_filtered.sort_values(by='amount_usd', ascending=False):\n",
    "  - .sort_values(): This method sorts the DataFrame.\n",
    "  - by='amount_usd': Specifies the column to sort by.\n",
    "  - ascending=False: Sorts the values in descending order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9660f09",
   "metadata": {},
   "source": [
    "6. Data Aggregation\n",
    "- Group the data by region and calculate: Total number of purchases, Average purchase amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0558f0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Aggregated data by region:\n",
      "         total_purchases  average_purchase_amount\n",
      "region                                           \n",
      "East                  92              1073.592026\n",
      "North                 79              1154.316652\n",
      "South                 73               944.079814\n",
      "Unknown               80              1065.436910\n",
      "West                  86              1041.619408\n"
     ]
    }
   ],
   "source": [
    "if 'region' in df.columns and 'amount_usd' in df.columns:\n",
    "    # Group the data by region\n",
    "    grouped_by_region = df.groupby('region')\n",
    "\n",
    "    # Calculate total number of purchases (count of rows in each group)\n",
    "    # and average purchase amount.\n",
    "    # We can use .agg() for multiple aggregations.\n",
    "    # 'size' will count rows per group for total_purchases.\n",
    "    # 'mean' will calculate average for amount_usd.\n",
    "    aggregated_data = grouped_by_region.agg(\n",
    "        total_purchases=('region', 'size'),  # Count occurrences for total purchases\n",
    "        average_purchase_amount=('amount_usd', 'mean') # Calculate mean for average amount\n",
    "    )\n",
    "\n",
    "    # Alternatively, for a simpler approach if just these two are needed:\n",
    "    # total_purchases_per_region = grouped_by_region.size().rename('total_purchases')\n",
    "    # average_amount_per_region = grouped_by_region['amount_usd'].mean().rename('average_purchase_amount')\n",
    "    # aggregated_data = pd.concat([total_purchases_per_region, average_amount_per_region], axis=1)\n",
    "\n",
    "\n",
    "    print(\"\\nAggregated data by region:\")\n",
    "    print(aggregated_data)\n",
    "else:\n",
    "    print(\"\\n'region' or 'amount_usd' column not found for aggregation.\")\n",
    "    aggregated_data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f68215",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "- df.groupby('region'): This method groups the DataFrame by unique values in the 'region' column. It creates a DataFrameGroupBy object.\n",
    "- .agg(...): The .agg() method allows you to apply multiple aggregation functions to the grouped data.\n",
    "  - total_purchases=('region', 'size'): This creates a new column 'total_purchases'. It applies the size function to the 'region' column within each group. size counts the number of rows in each group. You could use any existing non-null column with 'count' as well, e.g., ('name', 'count').\n",
    "  - average_purchase_amount=('amount_usd', 'mean'): This creates a new column 'average_purchase_amount' by calculating the mean of the 'amount_usd' column for each region group.\n",
    "- The result aggregated_data is a new DataFrame where the index is the 'region', and columns are 'total_purchases' and 'average_purchase_amount'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22aca078",
   "metadata": {},
   "source": [
    "7. New Column Creation\n",
    "- Create a column category:\n",
    "If amount_usd ≥1000 → “High”\n",
    "500≤ amount_usd <1000 → “Medium”\n",
    "Else → “Low”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "093cdafd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 5 rows with the new 'category' column:\n",
      "    amount_usd category\n",
      "0  1057.789098     High\n",
      "1  1805.620000     High\n",
      "2   168.440000      Low\n",
      "3  1057.789098     High\n",
      "4   267.390000      Low\n",
      "\n",
      "Value counts for the 'category' column:\n",
      "category\n",
      "High      236\n",
      "Medium     98\n",
      "Low        76\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "if 'amount_usd' in df.columns:\n",
    "    # Define a function to apply the categorization logic\n",
    "    def categorize_purchase(amount):\n",
    "        if pd.isna(amount): # Handle potential NaN values\n",
    "            return \"Unknown\" \n",
    "        if amount >= 1000:\n",
    "            return \"High\"\n",
    "        elif 500 <= amount < 1000:\n",
    "            return \"Medium\"\n",
    "        else:\n",
    "            return \"Low\"\n",
    "\n",
    "    # Apply the function to the 'amount_usd' column to create the 'category' column\n",
    "    df['category'] = df['amount_usd'].apply(categorize_purchase)\n",
    "\n",
    "    print(\"\\nFirst 5 rows with the new 'category' column:\")\n",
    "    print(df[['amount_usd', 'category']].head())\n",
    "\n",
    "    print(\"\\nValue counts for the 'category' column:\")\n",
    "    print(df['category'].value_counts())\n",
    "else:\n",
    "    print(\"\\n'amount_usd' column not found for category creation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196a3cac",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "- def categorize_purchase(amount): ...: This defines a custom Python function that takes an amount as input and returns the corresponding category string based on the specified conditions. It also handles potential NaN values in amount_usd by assigning them to an \"Unknown\" category.\n",
    "- df['amount_usd'].apply(categorize_purchase):\n",
    ".apply(): This method applies a function along an axis of the DataFrame. When used on a Series (like df['amount_usd']), it applies the function element-wise.\n",
    "categorize_purchase: The function to be applied to each value in the 'amount_usd' column.\n",
    "- The results are assigned to a new column called 'category' in the DataFrame df.\n",
    "- df['category'].value_counts(): This method returns a Series containing counts of unique values in the 'category' column, which is useful for seeing the distribution of categories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46106b6",
   "metadata": {},
   "source": [
    "8. Export\n",
    "- Save the cleaned and transformed DataFrame to a new CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f098f738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaned and transformed data saved to 'cleaned_sales_data.csv'\n",
      "\n",
      "Final shape of the DataFrame being saved:\n",
      "(410, 9)\n",
      "\n",
      "First 5 rows of the final DataFrame being saved:\n",
      "   customerid         name   age     product   amount_usd purchase_date  \\\n",
      "0        1000  Steve Davis  51.0      Laptop  1057.789098    2024-04-20   \n",
      "1        1001  Jane Miller  36.0      Tablet  1805.620000    2024-12-22   \n",
      "2        1002    Bob Smith  46.0      Tablet   168.440000    2024-04-20   \n",
      "3        1003   Emma Brown  51.0  Smartphone  1057.789098    2024-01-28   \n",
      "4        1004  Sara Miller  50.0      Tablet   267.390000    2024-03-15   \n",
      "\n",
      "  region  purchase_year category  \n",
      "0  South           2024     High  \n",
      "1  South           2024     High  \n",
      "2  South           2024      Low  \n",
      "3   West           2024     High  \n",
      "4  South           2024      Low  \n"
     ]
    }
   ],
   "source": [
    "# Define the output file path\n",
    "output_file_path = \"cleaned_sales_data.csv\" # Using a new name\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "# index=False prevents pandas from writing the DataFrame index as a column in the CSV.\n",
    "df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"\\nCleaned and transformed data saved to '{output_file_path}'\")\n",
    "print(\"\\nFinal shape of the DataFrame being saved:\")\n",
    "print(df.shape)\n",
    "print(\"\\nFirst 5 rows of the final DataFrame being saved:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fe4daf",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "- output_file_path = \"cleaned_sales_data_with_explanations.csv\": Defines the name for the output CSV file.\n",
    "- df.to_csv(output_file_path, index=False):\n",
    "  - .to_csv(): This method writes the DataFrame to a CSV file.\n",
    "  - output_file_path: The first argument is the path (including filename) where the CSV will be saved.\n",
    "  - index=False: This argument prevents pandas from writing the DataFrame's index as a column in the CSV file. If you want to include the index, you can set it to True or omit this argument (as True is the default for writing the index)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
